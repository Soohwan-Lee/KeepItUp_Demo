{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b1db05",
   "metadata": {},
   "source": [
    "# Skeleton Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c7d82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fdfdcc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 7778811572080542518\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 4163895296\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4026671103603663342\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93312cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' # 여러개 사용시 '0,1,2' 식으로 하나의 문자열에 입력\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU') # 호스트 러나임에 표시되는 GPU 장치 목록 반환\n",
    "\n",
    "if gpus: # 반환된 GPU 장치 목록이 있다면\n",
    "    try: # 해당 장치에 대한 메모리 증가 활성화 여부 설정\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError as e: # try문 실패시에 에러문구 출력\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93bce746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import socket\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae00920",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Model\n",
    "# model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "model = tf.saved_model.load('../model/moveNet/')\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# ### Load Video\n",
    "video_path = '../data/videos/'\n",
    "actionThree = video_path + 'actionPracticeWhite.mp4'\n",
    "\n",
    "### Draw EDGES\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "### Vector List\n",
    "vectorList = [\n",
    "    [0,1],\n",
    "    [0,2],\n",
    "    [1,3],\n",
    "    [2,4],\n",
    "    [3,5],\n",
    "    [0,6],\n",
    "    [1,7],\n",
    "    [6,7],\n",
    "    [6,8],\n",
    "    [7,9],\n",
    "    [8,10],\n",
    "    [9,10]\n",
    "]\n",
    "\n",
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)\n",
    "\n",
    "\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "\n",
    "\n",
    "\n",
    "### Variables for Calculating FPS\n",
    "prevTime = time.time() # previous time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ### Variables\n",
    "    numberOfPeople = 3\n",
    "\n",
    "    ### Loading Video File\n",
    "    cap = cv2.VideoCapture(actionThree)    ### Change the File Here!!\n",
    "    # cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    # cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "\n",
    "\n",
    "        ### Variables for each frame\n",
    "        initialTime = time.time()\n",
    "        \n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 128, 256)\n",
    "\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        # frame = cv2.resize(frame, (1280, 640))\n",
    "        \n",
    "        # Debug\n",
    "        firstTime = time.time()-initialTime\n",
    "        cv2.putText(frame, f'1: {round(firstTime,3)}', (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "        \n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        \n",
    "        # Debug\n",
    "        secondTime = time.time()-initialTime\n",
    "        cv2.putText(frame, f'2: {round(secondTime,3)}', (50,150), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "        # Get the keypoints_with_score\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "        keypoints_with_scores = keypoints_with_scores[:numberOfPeople]\n",
    "        \n",
    "        # Sort with each person from left to right\n",
    "        sorted_indices = np.argsort(keypoints_with_scores[:, 0, 1])\n",
    "        keypoints_with_scores = keypoints_with_scores[sorted_indices]\n",
    "        \n",
    "        keypoints_only = np.delete(keypoints_with_scores,2,2)\n",
    "        keypoints_only_body = np.delete(keypoints_only, [0,1,2,3,4], 1)\n",
    "        \n",
    "#         print(keypoints_with_scores)\n",
    "    \n",
    "\n",
    "        # Render keypoints \n",
    "        loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "#         loop_through_people(frame, [keypoints_with_scores[0]], EDGES, 0.1)    # Check for first person.....\n",
    "        \n",
    "        # Debug\n",
    "        thirdTime = time.time()-initialTime\n",
    "        cv2.putText(frame, f'3: {round(thirdTime,3)}', (50,200), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "\n",
    "    \n",
    "        ### Calculate & Print FPS\n",
    "        # Count Frame\n",
    "        curTime = time.time()\t# current time\n",
    "        fps = 1 / (curTime - prevTime)\n",
    "        prevTime = curTime\n",
    "        # Save FPS\n",
    "        fps_str = \"FPS : %0.1f\" %fps\n",
    "        # FPS print\n",
    "        cv2.putText(frame, fps_str, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        # Debug\n",
    "        fourthTime = time.time()-initialTime\n",
    "        cv2.putText(frame, f'3: {round(fourthTime,3)}', (50,250), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "        \n",
    "        cv2.imshow('Movenet Multipose', frame)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dd4bef",
   "metadata": {},
   "source": [
    "# Skeleton Overlay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d0096d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Model\n",
    "# model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "model = tf.saved_model.load('../model/moveNet/')\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# ### Load Video\n",
    "video_path = '../data/videos/'\n",
    "actionThree = video_path + 'actionPracticeWhite.mp4'\n",
    "\n",
    "### Draw EDGES\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "### Vector List\n",
    "vectorList = [\n",
    "    [0,1],\n",
    "    [0,2],\n",
    "    [1,3],\n",
    "    [2,4],\n",
    "    [3,5],\n",
    "    [0,6],\n",
    "    [1,7],\n",
    "    [6,7],\n",
    "    [6,8],\n",
    "    [7,9],\n",
    "    [8,10],\n",
    "    [9,10]\n",
    "]\n",
    "\n",
    "### Color for each person\n",
    "color_mapping = {\n",
    "    0: (255, 0, 0),\n",
    "    1: (0, 255, 0),\n",
    "    2: (0, 0, 255)\n",
    "}\n",
    "\n",
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold, movingArray):\n",
    "    for index, person in enumerate(keypoints_with_scores):\n",
    "        draw_connections(frame, person, edges, confidence_threshold, index, movingArray)\n",
    "        draw_keypoints(frame, person, confidence_threshold, index, movingArray)\n",
    "\n",
    "\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold, index, movingArray):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    movingArray = np.multiply(movingArray, x)\n",
    "    index = index * 2\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx + movingArray[index]), int(ky)), 3, color_mapping.get(index/2), -1)\n",
    "            cv2.circle(frame, (int(kx + movingArray[index + 1]), int(ky)), 3, color_mapping.get(index/2), -1)\n",
    "\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold, index, movingArray):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    movingArray = np.multiply(movingArray, x)\n",
    "    index = index * 2\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1 + movingArray[index]), int(y1)), (int(x2 + movingArray[index]), int(y2)), color_mapping.get(index/2), 2) # color[index]\n",
    "            cv2.line(frame, (int(x1 + movingArray[index + 1]), int(y1)), (int(x2 + movingArray[index + 1]), int(y2)), color_mapping.get(index/2), 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Variables for Calculating FPS\n",
    "prevTime = time.time() # previous time\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ### Variables\n",
    "    numberOfPeople = 3\n",
    "\n",
    "    ### Loading Video File\n",
    "    cap = cv2.VideoCapture(actionThree)    ### Change the File Here!!\n",
    "    # cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    # cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)\n",
    "\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "\n",
    "\n",
    "        ### Variables for each frame\n",
    "        initialTime = time.time()\n",
    "        \n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        # img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 128, 256)\n",
    "\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "\n",
    "        # frame = cv2.resize(frame, (1280, 640))\n",
    "        \n",
    "        \n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        \n",
    "        # Get the keypoints_with_score\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "        keypoints_with_scores = keypoints_with_scores[:numberOfPeople]\n",
    "        \n",
    "        # Sort with each person from left to right\n",
    "        sorted_indices = np.argsort(keypoints_with_scores[:, 0, 1])\n",
    "        keypoints_with_scores = keypoints_with_scores[sorted_indices]\n",
    "        \n",
    "        # Calculate the moving value\n",
    "        array = [keypoints_with_scores[0][0][1], keypoints_with_scores[1][0][1], keypoints_with_scores[2][0][1]]\n",
    "        movingArray = [array[j] - array[i] for i in range(len(array)) for j in range(len(array)) if i != j]\n",
    "\n",
    "        \n",
    "        keypoints_only = np.delete(keypoints_with_scores,2,2)\n",
    "        keypoints_only_body = np.delete(keypoints_only, [0,1,2,3,4], 1)\n",
    "        \n",
    "    \n",
    "\n",
    "        # Render keypoints \n",
    "        loop_through_people(frame, keypoints_with_scores, EDGES, 0.1, movingArray)\n",
    "#         loop_through_people(frame, [keypoints_with_scores[0]], EDGES, 0.1)    # Check for first person.....\n",
    "        \n",
    "        ### Calculate & Print FPS\n",
    "        # Count Frame\n",
    "        curTime = time.time()\t# current time\n",
    "        fps = 1 / (curTime - prevTime)\n",
    "        prevTime = curTime\n",
    "        # Save FPS\n",
    "        fps_str = \"FPS : %0.1f\" %fps\n",
    "        # FPS print\n",
    "        cv2.putText(frame, fps_str, (50,50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        \n",
    "        \n",
    "        cv2.imshow('Movenet Multipose', frame)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "80edd7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.4854421 , 0.20395182, 0.6718931 ],\n",
       "        [0.47991332, 0.20724404, 0.5304541 ],\n",
       "        [0.48052794, 0.20090774, 0.44115222],\n",
       "        [0.48525852, 0.21168628, 0.6180382 ],\n",
       "        [0.4859168 , 0.19741362, 0.79134315],\n",
       "        [0.5190614 , 0.22131728, 0.8225888 ],\n",
       "        [0.5166042 , 0.18492368, 0.8639576 ],\n",
       "        [0.55113435, 0.23791964, 0.78884435],\n",
       "        [0.5447781 , 0.16684686, 0.72380733],\n",
       "        [0.5857605 , 0.2243502 , 0.5733016 ],\n",
       "        [0.58175206, 0.18185203, 0.5992401 ],\n",
       "        [0.6047011 , 0.21357279, 0.7766479 ],\n",
       "        [0.60227334, 0.19243573, 0.8813506 ],\n",
       "        [0.67211854, 0.21876489, 0.84507024],\n",
       "        [0.6729254 , 0.18506305, 0.914375  ],\n",
       "        [0.73173904, 0.21951942, 0.74068433],\n",
       "        [0.73057175, 0.18054433, 0.79550105]],\n",
       "\n",
       "       [[0.47641063, 0.5523136 , 0.69520795],\n",
       "        [0.47099325, 0.5557912 , 0.48541242],\n",
       "        [0.46994138, 0.54950804, 0.4803882 ],\n",
       "        [0.47699547, 0.5591991 , 0.67051363],\n",
       "        [0.47606167, 0.54358554, 0.68181634],\n",
       "        [0.5166992 , 0.5693237 , 0.871571  ],\n",
       "        [0.5136714 , 0.53038996, 0.7934491 ],\n",
       "        [0.55143   , 0.58750594, 0.8090557 ],\n",
       "        [0.5453371 , 0.50998276, 0.8815521 ],\n",
       "        [0.58156395, 0.5736432 , 0.58769375],\n",
       "        [0.57941806, 0.52725095, 0.6324086 ],\n",
       "        [0.6048205 , 0.5605249 , 0.82793176],\n",
       "        [0.6060758 , 0.5367778 , 0.87329197],\n",
       "        [0.67918605, 0.56558055, 0.8534104 ],\n",
       "        [0.6824211 , 0.52919954, 0.90586567],\n",
       "        [0.7449323 , 0.5672938 , 0.8622155 ],\n",
       "        [0.7438332 , 0.52365124, 0.7996227 ]],\n",
       "\n",
       "       [[0.48445424, 0.8647935 , 0.7389942 ],\n",
       "        [0.47997653, 0.8686722 , 0.47353968],\n",
       "        [0.47886252, 0.86194676, 0.6580989 ],\n",
       "        [0.48585874, 0.87300473, 0.6304792 ],\n",
       "        [0.48546565, 0.8585043 , 0.6973424 ],\n",
       "        [0.5174875 , 0.8827721 , 0.8404583 ],\n",
       "        [0.5177713 , 0.8454418 , 0.8581559 ],\n",
       "        [0.5501138 , 0.8986289 , 0.8752535 ],\n",
       "        [0.54464674, 0.82915366, 0.8187343 ],\n",
       "        [0.58505934, 0.88514245, 0.6037857 ],\n",
       "        [0.5817633 , 0.8435134 , 0.5741237 ],\n",
       "        [0.6030029 , 0.8746605 , 0.7332134 ],\n",
       "        [0.6043393 , 0.854031  , 0.8471567 ],\n",
       "        [0.6728794 , 0.8794045 , 0.88974124],\n",
       "        [0.67456174, 0.8446164 , 0.9076328 ],\n",
       "        [0.7325534 , 0.88057345, 0.71392876],\n",
       "        [0.7299249 , 0.84242594, 0.68432593]]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keypoints_with_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d33c2d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences: [0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample 3-dimensional NumPy ndarray (3x3x3 array)\n",
    "sampleArray = np.array([\n",
    "    [[10, 20, 30], [40, 50, 60], [70, 80, 90]],\n",
    "    [[100, 200, 300], [400, 500, 600], [700, 800, 900]],\n",
    "    [[1000, 2000, 3000], [4000, 5000, 6000], [7000, 8000, 9000]]\n",
    "])\n",
    "\n",
    "# Extract the values and calculate differences\n",
    "differences = []\n",
    "\n",
    "for i in range(3):\n",
    "    diff_1 = sampleArray[0][i][1] - sampleArray[0][i][1]\n",
    "    diff_2 = sampleArray[0][i][1] - sampleArray[0][i][1]\n",
    "    differences.append(diff_1)\n",
    "    differences.append(diff_2)\n",
    "\n",
    "print(\"Differences:\", differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5b393dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Differences: [-30, -60, -300, -600, -3000, -6000]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample 3-dimensional NumPy ndarray (3x3x3 array)\n",
    "sampleArray = np.array([\n",
    "    [[10, 20, 30], [40, 50, 60], [70, 80, 90]],\n",
    "    [[100, 200, 300], [400, 500, 600], [700, 800, 900]],\n",
    "    [[1000, 2000, 3000], [4000, 5000, 6000], [7000, 8000, 9000]]\n",
    "])\n",
    "\n",
    "# Extract the values and calculate differences\n",
    "differences = []\n",
    "\n",
    "for i in range(3):\n",
    "    diff_1 = sampleArray[i][0][1] - sampleArray[i][0][1]\n",
    "    diff_2 = sampleArray[i][0][1] - sampleArray[i][0][1]\n",
    "    differences.append(diff_1)\n",
    "    differences.append(diff_2)\n",
    "\n",
    "print(\"Differences:\", differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "86297c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Array: [ 3  8 -3  5 -8 -5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input array\n",
    "array = np.array([0, 3, 8])\n",
    "\n",
    "# Calculate differences and create the result array\n",
    "result = []\n",
    "for i in range(len(array)):\n",
    "    for j in range(len(array)):\n",
    "        if i != j:\n",
    "            result.append(array[j] - array[i])\n",
    "\n",
    "# Convert the result list to a NumPy array\n",
    "result_array = np.array(result)\n",
    "\n",
    "print(\"Result Array:\", result_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ae41b216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_mapping = {\n",
    "    0: (255, 0, 0),\n",
    "    1: (0, 255, 0),\n",
    "    2: (0, 0, 255)\n",
    "}\n",
    "type(color_mapping[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a541d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color_numeric(a):\n",
    "    color_mapping = {\n",
    "        0: (255, 0, 0),\n",
    "        1: (0, 255, 0),\n",
    "        2: (0, 0, 255)\n",
    "    }\n",
    "\n",
    "    if a in color_mapping:\n",
    "        r, g, b = color_mapping[a]\n",
    "        return r * 65536 + g * 256 + b\n",
    "    else:\n",
    "        return None  # Return None for values of 'a' not in the mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03c6f0a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type((255,0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "90abc6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.33360875, 0.66047686, -0.33360875, 0.32686812, -0.66047686, -0.32686812]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movingArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9b1bb006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, x, c = frame.shape\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e00972a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = np.array([1, 2, 3])\n",
    "a = 10\n",
    "\n",
    "arr1 = np.multiply(arr1, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6435ef4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10, 20, 30])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2325d308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 255)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "color_mapping = {\n",
    "    0: (0, 0, 255),    # Blue\n",
    "    1: (0, 255, 0),    # Green\n",
    "    2: (255, 0, 0)     # Red\n",
    "}\n",
    "\n",
    "color = color_mapping.get(0)\n",
    "color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f505bb09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
