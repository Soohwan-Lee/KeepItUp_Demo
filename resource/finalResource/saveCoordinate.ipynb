{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c41b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import socket\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72ed23c",
   "metadata": {},
   "source": [
    "# Saving pandas dataframe as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "682735b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfPeople = 1\n",
    "num_coords = 17\n",
    "landmarks = ['t']\n",
    "for person in range(0, numberOfPeople):\n",
    "    for coords in range(0, num_coords):\n",
    "        landmarks += ['{}_y{}'.format(person, coords), '{}_x{}'.format(person, coords), '{}_s{}'.format(person, coords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17add95",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = '../../data/csv/'\n",
    "csv_name = 'actionPracticeGrandTruth.csv'\n",
    "with open(csv_path + csv_name, mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6964cbed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 88>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    100\u001b[0m BPD \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m# Resize image\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m()\n\u001b[0;32m    104\u001b[0m img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mresize_with_pad(tf\u001b[38;5;241m.\u001b[39mexpand_dims(img, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m384\u001b[39m,\u001b[38;5;241m640\u001b[39m)\n\u001b[0;32m    105\u001b[0m input_img \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mcast(img, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "### Optional if you are using a GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "### Load Model\n",
    "model = hub.load('https://tfhub.dev/google/movenet/multipose/lightning/1')\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "### Load Video\n",
    "video_path = '../../data/videos/'\n",
    "actionPractice = video_path + 'actionPracticeSmall.mp4'\n",
    "\n",
    "### Set CSV\n",
    "csv_path = '../../data/csv/'\n",
    "\n",
    "### Draw EDGES\n",
    "EDGES = {\n",
    "    (0, 1): 'm',\n",
    "    (0, 2): 'c',\n",
    "    (1, 3): 'm',\n",
    "    (2, 4): 'c',\n",
    "    (0, 5): 'm',\n",
    "    (0, 6): 'c',\n",
    "    (5, 7): 'm',\n",
    "    (7, 9): 'm',\n",
    "    (6, 8): 'c',\n",
    "    (8, 10): 'c',\n",
    "    (5, 6): 'y',\n",
    "    (5, 11): 'm',\n",
    "    (6, 12): 'c',\n",
    "    (11, 12): 'y',\n",
    "    (11, 13): 'm',\n",
    "    (13, 15): 'm',\n",
    "    (12, 14): 'c',\n",
    "    (14, 16): 'c'\n",
    "}\n",
    "\n",
    "### Vector List\n",
    "vectorList = [\n",
    "    [0,1],\n",
    "    [0,2],\n",
    "    [1,3],\n",
    "    [2,4],\n",
    "    [3,5],\n",
    "    [0,6],\n",
    "    [1,7],\n",
    "    [6,7],\n",
    "    [6,8],\n",
    "    [7,9],\n",
    "    [8,10],\n",
    "    [9,10]\n",
    "]\n",
    "\n",
    "# Function to loop through each person detected and render\n",
    "def loop_through_people(frame, keypoints_with_scores, edges, confidence_threshold):\n",
    "    for person in keypoints_with_scores:\n",
    "        draw_connections(frame, person, edges, confidence_threshold)\n",
    "        draw_keypoints(frame, person, confidence_threshold)\n",
    "\n",
    "\n",
    "def draw_keypoints(frame, keypoints, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for kp in shaped:\n",
    "        ky, kx, kp_conf = kp\n",
    "        if kp_conf > confidence_threshold:\n",
    "            cv2.circle(frame, (int(kx), int(ky)), 3, (0,255,0), -1)\n",
    "\n",
    "def draw_connections(frame, keypoints, edges, confidence_threshold):\n",
    "    y, x, c = frame.shape\n",
    "    shaped = np.squeeze(np.multiply(keypoints, [y,x,1]))\n",
    "    \n",
    "    for edge, color in edges.items():\n",
    "        p1, p2 = edge\n",
    "        y1, x1, c1 = shaped[p1]\n",
    "        y2, x2, c2 = shaped[p2]\n",
    "        \n",
    "        if (c1 > confidence_threshold) & (c2 > confidence_threshold):      \n",
    "            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0,0,255), 2)\n",
    "\n",
    "\n",
    "###\n",
    "# Variables for drawing plot in real-time\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ### Variables\n",
    "#     numberOfPeople = 1    ### Change the number of people here!!\n",
    "    \n",
    "    start = time.time()\n",
    "\n",
    "    ### Loading Video File\n",
    "    cap = cv2.VideoCapture(actionPractice)    ### Change the File Here!!\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        ### Variables for each frame\n",
    "        BPD = []\n",
    "        \n",
    "        # Resize image\n",
    "        img = frame.copy()\n",
    "        img = tf.image.resize_with_pad(tf.expand_dims(img, axis=0), 384,640)\n",
    "        input_img = tf.cast(img, dtype=tf.int32)\n",
    "        \n",
    "        # Detection section\n",
    "        results = movenet(input_img)\n",
    "        keypoints_with_scores = results['output_0'].numpy()[:,:,:51].reshape((6,17,3))\n",
    "        keypoints_with_scores = keypoints_with_scores[:numberOfPeople]\n",
    "        keypoints_only = np.delete(keypoints_with_scores,2,2)\n",
    "        keypoints_only_body = np.delete(keypoints_only, [0,1,2,3,4], 1)\n",
    "        \n",
    "#         print(keypoints_with_scores)    # This is coordinates data.\n",
    "#         print(time.time() - start)    # This is program running time.\n",
    "        \n",
    "        # Make coordinates flatten\n",
    "        row = []\n",
    "        for person in range(0, numberOfPeople):\n",
    "            tempRow = list(np.array([[keypoint[0], keypoint[1], keypoint[2]] for keypoint in keypoints_with_scores[person]]).flatten())\n",
    "            row.append(tempRow)\n",
    "        \n",
    "        row.sort(key=lambda x: (x[1], x[0]))    # sorted with order of people (from left to right)\n",
    "        row = sum(row, [])    # Convert 2-dim List to flat\n",
    "\n",
    "        # Append time series\n",
    "        row.insert(0, time.time()-start)\n",
    "        \n",
    "        # Export to CSV\n",
    "        with open(csv_path + csv_name, mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(row)\n",
    "\n",
    "\n",
    "        # Render keypoints \n",
    "        loop_through_people(frame, keypoints_with_scores, EDGES, 0.1)\n",
    "#         loop_through_people(frame, [keypoints_with_scores[0]], EDGES, 0.1)    # Check for first person.....\n",
    "\n",
    "        \n",
    "        cv2.imshow('Movenet Multipose', frame)\n",
    "        \n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccd27f7",
   "metadata": {},
   "source": [
    "# Filtered Data with FPS 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "097089a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data saved to 'filtered_data.csv'\n"
     ]
    }
   ],
   "source": [
    "# Read the original CSV file and filter the rows\n",
    "filtered_rows = []\n",
    "with open(csv_path + 'actionPracticeGrandTruth.csv', 'r') as input_file:\n",
    "    reader = csv.reader(input_file)\n",
    "    header = next(reader)  # Read and skip the header row\n",
    "\n",
    "    for index, row in enumerate(reader):\n",
    "        if index % 10 == 0:\n",
    "            filtered_rows.append(row)\n",
    "\n",
    "# Write the filtered rows to a new CSV file\n",
    "with open(csv_path + 'actionPracticeGrandTruth_filtered.csv', 'w', newline='') as output_file:\n",
    "    writer = csv.writer(output_file)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(filtered_rows)\n",
    "\n",
    "print(\"Filtered data saved to 'filtered_data.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729c3860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
